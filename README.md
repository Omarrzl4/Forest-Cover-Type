# ğŸŒ² Forest Cover Type Classification (TPS - Dec 2021)

This repository contains a solution to the **Tabular Playground Series - December 2021** Kaggle competition. The goal is to predict the **forest cover type** based on a variety of cartographic and environmental features using XGBoost.

---# ğŸŒ² Forest Cover Type Prediction with XGBoost

## ğŸ“Œ Project Overview

This machine learning project predicts **forest cover types** using cartographic and environmental features. Built using the [Kaggle Tabular Playground Series - December 2021](https://www.kaggle.com/competitions/tabular-playground-series-dec-2021) dataset, it applies the powerful **XGBoost** algorithm for multi-class classification.

---

## ğŸ“‚ Dataset

- **Source**: Kaggle TPS Dec 2021
- **Train File**: `train.csv`
- **Test File**: `test.csv`
- **Target**: `Cover_Type` (7 possible forest categories)

### ğŸ” Selected Features

- `Elevation`, `Aspect`, `Slope`
- `Horizontal_Distance_To_Hydrology`
- `Vertical_Distance_To_Hydrology`
- `Horizontal_Distance_To_Roadways`
- `Horizontal_Distance_To_Fire_Points`
- `Wilderness_Area` and `Soil_Type` features (excluding types 20â€“40)

---

## ğŸ§ª Data Preprocessing

- Loaded data using **Pandas**
- Sampled **10,000 rows** for fast experimentation
- Dropped soil types 20â€“40 to reduce dimensionality
- Checked for missing values (none found)
- Split data into features `X` and label `y`
- Applied **StandardScaler** for normalization
- Encoded labels using **LabelEncoder**
- Split into:
  - 80% Training
  - 20% Validation

---

## ğŸ§  Model: XGBoost Classifier

- **Base model**: `XGBClassifier` from `xgboost` library
- **Key Parameters**:
  - `use_label_encoder=False`
  - `eval_metric='mlogloss'`
  - `random_state=42`

### âš™ï¸ Compilation

- Objective: Multi-class classification
- Evaluation Metric: **Log Loss (mlogloss)**

---

## ğŸ‹ï¸ Training

- Fit model on training data
- Made predictions on validation data
- Evaluated with:
  - `classification_report` (precision, recall, F1)
  - `confusion_matrix`

---

## ğŸ“ˆ Evaluation

- Output: Full classification report for each forest type
- Visualized Confusion Matrix using `matplotlib` and `ConfusionMatrixDisplay`

---

## ğŸ“Š Results

- Achieved solid performance on validation data
- Confusion matrix revealed class distribution and model accuracy
- Future improvements may include:
  - Feature engineering
  - Full dataset training
  - Hyperparameter tuning (GridSearch or Optuna)

---

## ğŸ§° Technologies Used

- **Programming Language**: Python
- **Libraries**:
  - XGBoost
  - Pandas
  - NumPy
  - scikit-learn
  - Matplotlib
  - Seaborn

---

## ğŸ‘¨â€ğŸ’» Author

**Omar Al Zoghbi**

---

## ğŸ“ Optional Enhancements

- ğŸ“Š Add feature importance plots
- ğŸ§ª Include hyperparameter tuning
- ğŸ’¾ Provide `requirements.txt` for full reproducibility



## ğŸ“¦ Dataset

The dataset includes:

- `train.csv` â€” Training data with features and `Cover_Type` labels.
- `test.csv` â€” Test data with the same features but without labels.
- `sample_submission.csv` â€” Submission format example.

ğŸ“Œ [Kaggle competition link](https://www.kaggle.com/competitions/tabular-playground-series-dec-2021)

---

## âš™ï¸ Environment Setup

```python
# Upload kaggle.json API key
from google.colab import files
files.upload()

# Setup Kaggle credentials
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download and unzip the competition data
!kaggle competitions download -c tabular-playground-series-dec-2021
!unzip tabular-playground-series-dec-2021.zip
